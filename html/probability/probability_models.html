<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Probability Models</title>
    <link rel="stylesheet" href="/styles/styles.css">
    <script src="/js/script.js"></script>
</head>
<body>

<div class="thin-wrapper">

    <div class="definition" id="definition-probability-model">
        <div class="title">Probability Model</div>
        <div class="content">
            A probability model consists of a non-empty set called the sample space \( \Omega  \), a collection of events that are subsets of \( S \) and a probability measure \( P \) assigning a probability between 0 and 1 to each event with \( P \left( \emptyset  \right) = 0  \) and \( P \left( S \right) = 1 \) and with \( P \) additive.
        </div>
    </div>



    <div class="definition" id="definition-discrete-uniform-distribution">
        <div class="title">Finite Uniform Distribution</div>
        <div class="content">
            For any specific \( N \in \mathbb{N} \) , the random variable \( X \) is said to have a (finite discrete) uniform distribution on the sample space \( \Omega=\{1, \ldots, N\} \) - denoted: \( X \sim \) unif \(\{1, \ldots, N\}\) iff
            \[
            P(X=k)=1 / N, \quad k=1, \ldots, N .
            \]
        </div>
    </div>

    <div class="definition" id="definition-conditional-probability">
        <div class="title">Conditional Probability</div>
        <div class="content">
            Let \( A, B \subseteq \Omega  \), such that \( P \left( B \right) \neq 0 \) then the conditional probability of \( A \) given \( B \) is defined as
            \[
            P \left( A \mid B \right) = \frac{P \left( A \cap B \right) }{ P \left( B \right) }
            \]
        </div>
    </div>

    <div class="corollary" id="corollary-intersection-as-conditional-probability">
        <div class="title">Intersection as Conditional Probability</div>
        <div class="content">
            Suppose that \( P \left( A \right) , P \left( B \right) \neq 0 \) then we have
            \[
            P \left( A \cap B \right) = P \left( A \mid B \right) P \left( B \right)
            \]
        </div>
        <div class="proof">

        </div>
    </div>

    <div class="corollary" id="corollary-symmetric-conditional-equation">
        <div class="title">Symmetric Conditional Equation</div>
        <div class="content">
            \[
            P \left( A \mid B \right) P \left( B \right) = P \left( B \mid A \right) P \left( A \right)
            \]
        </div>
        <div class="proof">
        </div>
    </div>


    <div class="proposition" id="proposition-probability-of-set-difference">
        <div class="title">Probability of Set Difference</div>
        <div class="content">
            Suppose that \( A, B \subseteq \Omega  \) then
            \[
            P \left( A \setminus B \right) = P \left( A \right) - P \left( A \cap B \right)
            \]
        </div>
        <div class="proof">

        </div>
    </div>


    <div class="lemma" id="lemma-probability-of-event-via-partition">
        <div class="title">Probability of an Event through a Partition</div>
        <div class="content">
            Suppose that \( \mathcal{ X }  = \left\{ X _ 1,  X _ 2, \ldots  \right\}  \) is a partition of \( \Omega  \) then for any event \( E \) we have
            \[
            P \left( E \right) = \sum _ { i \in \mathbb{ N } _ 1 } P \left(  E \cap X _ i  \right)
            \]
        </div>
        <div class="proof">
            <p>
                Observe that \( E = E \cap \Omega = E \cap \left( \sqcup _ { i \in \mathbb{ N } _ 1 } X _ i  \right) = \sqcup _ { i \in \mathbb{ N } _ 1 } \left( E \cap X _ i \right)    \), therefore
                \[
                P \left( E  \right) = \sum _ { i \in \mathbb{ N } _ 1 } P \left( E \cap X _ i \right)
                \]
            </p>
        </div>
    </div>

    <p>
        It follows as an easy corollary that it holds for finite partitions by seting the rest of the partition to be the empty set.
    </p>

    <div class="theorem" id="theorem-law-of-total-probability">
        <div class="title">Law of Total Probability</div>
        <div class="content">
            Suppose that \( \mathcal{ X }  = \left\{ X _ 1,  X _ 2, \ldots  \right\}  \) is a partition of \( \Omega  \) then for any event \( E \) we have
            \[
            P \left( E \right) = \sum _ { i \in \mathbb{ N } _ 1 } P \left( E \mid X _ i \right) P \left( X _ i \right)
            \]
        </div>
        <div class="proof">

        </div>
    </div>


    <div class="definition" id="definition-independence-of-events">
        <div class="title">Independence of Events</div>
        <div class="content">
            Given two events \( A, B \subseteq \Omega  \) we say that \( A \) and \( B \)re independent iff
            \[
            P \left( A | B \right) = P \left( A \right)
            \]
        </div>
    </div>

    <div class="corollary" id="corollary-independence-is-symmetric">
        <div class="title">Independence is Symmetric</div>
        <div class="content">
            Suppose that \( A \) and \( B \) are independent, then \( B \) and \( A \) are independent
        </div>
        <div class="proof">
            <p>
                We know that \( P \left( A \mid B   \right) =  P \left( A \right) \), we'd like to prove that \( P \left( B \mid A \right) = P \left( B \right)   \),
                \[
                \begin{align}
                P \left( B \mid A \right) &= \frac{P \left( A \cap B \right) }{ P \left( A \right) } \\
                &= \frac{P \left( A \mid B \right) P \left( B \right)  }{ P \left( A \mid B \right) } \\
                &= P \left( B \right)
                \end{align}
                \]
                on the second line we used the <a class="knowledge-link" href="/probability/scratch/proper.html#corollary-intersection-as-conditional-probability">intersection as conditional formula</a>
            </p>
        </div>
    </div>

    <hr>

    <div class="definition" id="definition-statistically-independent">
        <div class="title">Independent Random Variables</div>
        <div class="content">
            Suppose that \( X, Y \) are two random variables, we say that \( X \) and \( Y \) are independent and write \( X \perp Y \) iff given any \( A, B \subseteq \mathbb{ R }  \) such that \( P \left( Y \in B \right) \neq 0  \)  we have that
            \[
            P \left( X \in A | Y \in B \right) = P \left( X \in A \right)
            \]
        </div>
    </div>

    <div class="corollary" id="corollary-independence-as-a-product">
        <div class="title">Independence as a Product</div>
        <div class="content">
            \[
            A \perp B \iff P \left( X \in A \cap X \in B \right) = P \left( X \in A \right) P \left( X \in B \right)
            \]
        </div>
        <div class="proof">
            We know that the following holds by this fact:
            \[
            P \left( A \cap B \right) = P \left( A \mid B\right)  P \left( B \right)
            \]
            therefore since we assumed \( A \perp B \) we know that \( P \left( A \mid B \right) = P \left( A \right)   \) and thus we have
            \[
            P \left( A \cap B \right) =  P \left( A  \right) P \left( B \right)
            \]
            as needed.
        </div>
    </div>

    <div class="corollary" id="corollary-independence-is-reflexive">
        <div class="title">Independence is Reflexive</div>
        <div class="content">
            \[
            A \perp B \iff B \perp A
            \]
        </div>
        <div class="proof">
            Follows from the previous corollary.
        </div>
    </div>

    <div class="exercise" id="exercise-independence-practice">
        <div class="title">Independence Practice</div>
        <div class="content">
            Suppose that \( A, B \) are two events such that \( P \left( A \setminus B  \right) = P \left( B \right) = \frac{2}{5}    \) and \( A \perp B \):
            <ul>
                <li>Determine \( P \left( A \right)  \) </li>
                <li>Obtain the probabilities \( P \left( A \cap B \right), P \left( A \cap B ^ \complement \right) , P \left( A ^ \complement \cap B ^ \complement \right)   \) </li>
                <li>
                    Determine the conditional probability \( P \left( A \setminus B \mid A \cap B \right)  \)
                </li>
            </ul>
        </div>
        <div class="proof">
            <p>
                We start by determining \( P \left( A \right)  \), firstly <a class="knowledge-link" href="/probability/scratch/proper.html#proposition-probability-of-set-difference">we know that</a>
                \[
                \begin{align}
                \frac{2}{5} &= P \left( B \right) = P \left( A \setminus B \right) \\
                &= P \left( A \right) - P \left( A \cap B \right) \\
                &= P \left( A \right) - P \left( A  \right) P \left( B \right)  \\
                &= P \left( A \right) \left( 1 - P \left( B \right)  \right) \\
                &= P \left( A \right) \left( 1 - \frac{2}{5}  \right) \\
                &= P \left( A \right) \left( \frac{3}{5}  \right)
                \end{align}
                \]
                therefore we deduce that \( P \left( A \right) = \frac{2}{3}  \)
            </p>

        </div>
    </div>

    <div class="definition" id="definition-collection-of-independent-events">
        <div class="title">Collection of Independent Events</div>
        <div class="content">
            Suppose we have some collection \( A _ i, i \in I  \) of events for some index set \( I \), then we say that this collection of events are independent if

        </div>
    </div>



</div>


</body>
</html>