<div class="definition" id="definition-probability-model">
    <div class="title">
        Probability Model
    </div>
    <div class="content">
        A probability model consists of a non-empty set called the sample space \( \Omega \), a collection of events that are subsets of \( S \) and a probability measure \( P \) assigning a probability between 0 and 1 to each event with \( P \left( \emptyset \right) = 0 \) and \( P \left( S \right) = 1 \) and with \( P \) additive.
    </div>
</div>
<div class="definition" id="definition-discrete-uniform-distribution">
    <div class="title">
        Finite Uniform Distribution
    </div>
    <div class="content">
        For any specific \( N \in \mathbb{N} \) , the random variable \( X \) is said to have a (finite discrete) uniform distribution on the sample space \( \Omega=\{1, \ldots, N\} \) - denoted: \( X \sim \) unif \(\{1, \ldots, N\}\) iff \[ P(X=k)=1 / N, \quad k=1, \ldots, N . \]
    </div>
</div>
<div class="definition" id="definition-conditional-probability">
    <div class="title">
        Conditional Probability
    </div>
    <div class="content">
        Let \( A, B \subseteq \Omega \), such that \( P \left( B \right) \neq 0 \) then the conditional probability of \( A \) given \( B \) is defined as \[ P \left( A \mid B \right) = \frac{P \left( A \cap B \right) }{ P \left( B \right) } \] if \( P \left( B \right) = 0 \) then we define \( P \left( A \mid B \right) = 0 \)
    </div>
</div>
<div class="corollary" id="corollary-intersection-as-conditional-probability">
    <div class="title">
        Intersection as Conditional Probability
    </div>
    <div class="content">
        Suppose that \( P \left( A \right) , P \left( B \right) \neq 0 \) then we have \[ P \left( A \cap B \right) = P \left( A \mid B \right) P \left( B \right) \]
    </div>
    <div class="proof"></div>
</div>
<div class="lemma" id="lemma-finite-intersection-as-conditional-probability">
    <div class="title">
        Finite Intersection as Conditional Probability
    </div>
    <div class="content">
        Suppose we have events \( E _ 1, \ldots , E _ n \) then \[ P \left( E _ 1 \cap E _ 2 \cap \cdots \cap E _ n \right) = P \left( E _ n | \left( E _ 1 \cap \cdots \cap E _ { n - 1 } \right) \right) P \left( E _ 1 \cap \cdots \cap E _ { n - 1 } \right) \] whenever \( P \left( E _ 1 \cap E _ 2 \cap \cdots \cap E _ n \right) \neq 0 \)
    </div>
    <div class="proof">
        Let \( A := E _ 1 \cap \cdots \cap E _ { n - 1 } \) and \( B := E _ n \) then from <a class="knowledge-link" href="/probability/probability_models.html#corollary-intersection-as-conditional-probability">this</a> we recall that: \[ P \left( B \cap A \right) = P \left( B \mid A \right) P \left( B \right) \] Since \( P \left( B \cap A \right) = P \left( A \cap B \right) \) we have that \[ P \left( \left( E _ 1 \cap E _ 2 \cap \cdots \cap E _ { n - 1 } \right) \cap E _ n \right) = P \left( E _ n \mid \left( E _ 1 \cap E _ 2 \cap \cdots \cap E _ { n - 1 } \right) \right) \cdot P \left( E _ 1 \cap \cdots \cap E _ { n - 1 } \right) \]
    </div>
</div>
<div class="theorem" id="theorem-product-rule">
    <div class="title">
        Product Rule
    </div>
    <div class="content">
        Let \( E _ 1, \ldots , E _ n \) be events, then \[ P \left( \left( E _ 1 \cap E _ 2 \cap \cdots \cap E _ { n - 1 } \right) \cap E _ n \right) = P \left( E _ n \mid \left( E _ 1 \cap E _ 2 \cap \cdots \cap E _ { n - 1 } \right) \right) \cdot P \left( E _ { n - 1 } \mid \left( E _ 1 \cap \cdots \cap E _ { n - 2 } \right) \right) \cdots P \left( E _ 3 \mid \left( E _ 1 \cap E _ 2 \right) \right) \cdot P \left( E _ 2 \mid E _ 1 \right) P \left( E _ 1 \right) \]
    </div>
    <div class="proof">
        Proof by induction and using the previous lemma during the induction step and the "intersection as conditional probability" for the base case.
    </div>
</div>
<p>As stated it is notationally unwieldly we can clean it up using the following: \[ P \left( \left( E _ 1 \cap E _ 2 \cap \cdots \cap E _ { n - 1 } \right) \cap E _ n \right) = P \left( E _ 1 \right) \left( \prod _ {j = 2} ^ n P \left( E _ j \mid \left( E _ 1 \cap \cdots \cap E _ { j - 1 } \right) \right)\right) \] If you're confused by the usage of \( \prod \) note that each factor uses exactly one more \( E _ i \) than the previous and moves in the reverse order of the of the original inequality</p>
<div class="corollary" id="corollary-symmetric-conditional-equation">
    <div class="title">
        Symmetric Conditional Equation
    </div>
    <div class="content">
        \[ P \left( A \mid B \right) P \left( B \right) = P \left( B \mid A \right) P \left( A \right) \]
    </div>
    <div class="proof"></div>
</div>
<div class="proposition" id="proposition-probability-of-set-difference">
    <div class="title">
        Probability of Set Difference
    </div>
    <div class="content">
        Suppose that \( A, B \subseteq \Omega \) then \[ P \left( A \setminus B \right) = P \left( A \right) - P \left( A \cap B \right) \]
    </div>
    <div class="proof"></div>
</div>
<div class="lemma" id="lemma-probability-of-event-via-partition">
    <div class="title">
        Probability of an Event through a Partition
    </div>
    <div class="content">
        Suppose that \( \mathcal{ X } = \left\{ X _ 1, X _ 2, \ldots \right\} \) is a partition of \( \Omega \) then for any event \( E \) we have \[ P \left( E \right) = \sum _ { i \in \mathbb{ N } _ 1 } P \left( E \cap X _ i \right) \]
    </div>
    <div class="proof">
        <p>Observe that \( E = E \cap \Omega = E \cap \left( \sqcup _ { i \in \mathbb{ N } _ 1 } X _ i \right) = \sqcup _ { i \in \mathbb{ N } _ 1 } \left( E \cap X _ i \right) \), therefore \[ P \left( E \right) = \sum _ { i \in \mathbb{ N } _ 1 } P \left( E \cap X _ i \right) \]</p>
    </div>
</div>
<p>It follows as an easy corollary that it holds for finite partitions by seting the rest of the partition to be the empty set.</p>
<div class="theorem" id="theorem-law-of-total-probability">
    <div class="title">
        Law of Total Probability
    </div>
    <div class="content">
        Suppose that \( \mathcal{ X } = \left\{ X _ 1, X _ 2, \ldots \right\} \) is a partition of \( \Omega \) then for any event \( E \) we have \[ P \left( E \right) = \sum _ { i \in \mathbb{ N } _ 1 } P \left( E \mid X _ i \right) P \left( X _ i \right) \]
    </div>
    <div class="proof"></div>
</div>
<div class="definition" id="definition-independence-of-events">
    <div class="title">
        Independence of Events
    </div>
    <div class="content">
        Given two events \( A, B \subseteq \Omega \) we say that \( A \) and \( B \)re independent iff \[ P \left( A | B \right) = P \left( A \right) \]
    </div>
</div>
<div class="corollary" id="corollary-independence-is-symmetric">
    <div class="title">
        Independence is Symmetric
    </div>
    <div class="content">
        Suppose that \( A \) and \( B \) are independent, then \( B \) and \( A \) are independent
    </div>
    <div class="proof">
        <p>We know that \( P \left( A \mid B \right) = P \left( A \right) \), we'd like to prove that \( P \left( B \mid A \right) = P \left( B \right) \), \[ \begin{align} P \left( B \mid A \right) &amp;= \frac{P \left( A \cap B \right) }{ P \left( A \right) } \\ &amp;= \frac{P \left( A \mid B \right) P \left( B \right) }{ P \left( A \mid B \right) } \\ &amp;= P \left( B \right) \end{align} \] on the second line we used the <a class="knowledge-link" href="/probability/scratch/proper.html#corollary-intersection-as-conditional-probability">intersection as conditional formula</a></p>
    </div>
</div>
<hr>
